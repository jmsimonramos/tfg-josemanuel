{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import validation_curve\n",
    "import pickle\n",
    "import sklearn.model_selection as ms\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   id_leg  operation  runway  hexid  callsign  type  origin  destination  \\\n0  733513          0       5    483      6920    22     186          268   \n1  733498          0       5    515       246    23     664          268   \n2  733495          0       5    814       262    67     212          268   \n3  733501          0       5    625       277    23     254          268   \n4  733496          0       5    491       268    23     421          268   \n\n   altitude  ground_speed  vertical_rate  tmp  dew_pt  rel_hum  wind_dir  \\\n0    1625.0         142.0         -768.0  7.0     0.0   61.017     250.0   \n1    1850.0         137.0         -768.0  7.0    -1.0   56.724     250.0   \n2    2200.0         156.0         -832.0  7.0    -1.0   56.724     230.0   \n3    1862.5         143.0         -640.0  7.0    -1.0   56.724     230.0   \n4    2000.0         136.0         -640.0  5.0     0.0   70.063     160.0   \n\n   win_sp  wind_gust  visib   press  sky_lvl  rain  snow  drizzle  fog  \\\n0  20.372   0.000000   10.0  1030.0     10.0   0.0   0.0      0.0  0.0   \n1  25.928  44.447962   10.0  1030.0     10.0   0.0   0.0      0.0  0.0   \n2  16.668   0.000000   10.0  1031.0     10.0   0.0   0.0      0.0  0.0   \n3  16.668   0.000000   10.0  1031.0     10.0   0.0   0.0      0.0  0.0   \n4  12.964   0.000000   10.0  1031.0     10.0   0.0   0.0      0.0  0.0   \n\n   time_class  day_week  month  time_ref  operation_Landing  \\\n0         2.0       1.0    1.0       6.0                1.0   \n1         3.0       1.0    1.0       7.0                1.0   \n2         3.0       1.0    1.0       8.0                1.0   \n3         3.0       1.0    1.0       8.0                1.0   \n4         4.0       1.0    1.0       9.0                1.0   \n\n   operation_TakeOff  runway_14L  runway_14R  runway_18L  runway_18R  \\\n0                0.0         0.0         0.0         0.0         0.0   \n1                0.0         0.0         0.0         0.0         0.0   \n2                0.0         0.0         0.0         0.0         0.0   \n3                0.0         0.0         0.0         0.0         0.0   \n4                0.0         0.0         0.0         0.0         0.0   \n\n   runway_32L  runway_32R  runway_36L  runway_36R  configuration_NORTE  \\\n0         0.0         1.0         0.0         0.0                    1   \n1         0.0         1.0         0.0         0.0                    1   \n2         0.0         1.0         0.0         0.0                    1   \n3         0.0         1.0         0.0         0.0                    1   \n4         0.0         1.0         0.0         0.0                    1   \n\n   configuration_SUR  configuration  \n0                  0              0  \n1                  0              0  \n2                  0              0  \n3                  0              0  \n4                  0              0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_leg</th>\n      <th>operation</th>\n      <th>runway</th>\n      <th>hexid</th>\n      <th>callsign</th>\n      <th>type</th>\n      <th>origin</th>\n      <th>destination</th>\n      <th>altitude</th>\n      <th>ground_speed</th>\n      <th>vertical_rate</th>\n      <th>tmp</th>\n      <th>dew_pt</th>\n      <th>rel_hum</th>\n      <th>wind_dir</th>\n      <th>win_sp</th>\n      <th>wind_gust</th>\n      <th>visib</th>\n      <th>press</th>\n      <th>sky_lvl</th>\n      <th>rain</th>\n      <th>snow</th>\n      <th>drizzle</th>\n      <th>fog</th>\n      <th>time_class</th>\n      <th>day_week</th>\n      <th>month</th>\n      <th>time_ref</th>\n      <th>operation_Landing</th>\n      <th>operation_TakeOff</th>\n      <th>runway_14L</th>\n      <th>runway_14R</th>\n      <th>runway_18L</th>\n      <th>runway_18R</th>\n      <th>runway_32L</th>\n      <th>runway_32R</th>\n      <th>runway_36L</th>\n      <th>runway_36R</th>\n      <th>configuration_NORTE</th>\n      <th>configuration_SUR</th>\n      <th>configuration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>733513</td>\n      <td>0</td>\n      <td>5</td>\n      <td>483</td>\n      <td>6920</td>\n      <td>22</td>\n      <td>186</td>\n      <td>268</td>\n      <td>1625.0</td>\n      <td>142.0</td>\n      <td>-768.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>61.017</td>\n      <td>250.0</td>\n      <td>20.372</td>\n      <td>0.000000</td>\n      <td>10.0</td>\n      <td>1030.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>733498</td>\n      <td>0</td>\n      <td>5</td>\n      <td>515</td>\n      <td>246</td>\n      <td>23</td>\n      <td>664</td>\n      <td>268</td>\n      <td>1850.0</td>\n      <td>137.0</td>\n      <td>-768.0</td>\n      <td>7.0</td>\n      <td>-1.0</td>\n      <td>56.724</td>\n      <td>250.0</td>\n      <td>25.928</td>\n      <td>44.447962</td>\n      <td>10.0</td>\n      <td>1030.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>733495</td>\n      <td>0</td>\n      <td>5</td>\n      <td>814</td>\n      <td>262</td>\n      <td>67</td>\n      <td>212</td>\n      <td>268</td>\n      <td>2200.0</td>\n      <td>156.0</td>\n      <td>-832.0</td>\n      <td>7.0</td>\n      <td>-1.0</td>\n      <td>56.724</td>\n      <td>230.0</td>\n      <td>16.668</td>\n      <td>0.000000</td>\n      <td>10.0</td>\n      <td>1031.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>733501</td>\n      <td>0</td>\n      <td>5</td>\n      <td>625</td>\n      <td>277</td>\n      <td>23</td>\n      <td>254</td>\n      <td>268</td>\n      <td>1862.5</td>\n      <td>143.0</td>\n      <td>-640.0</td>\n      <td>7.0</td>\n      <td>-1.0</td>\n      <td>56.724</td>\n      <td>230.0</td>\n      <td>16.668</td>\n      <td>0.000000</td>\n      <td>10.0</td>\n      <td>1031.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>733496</td>\n      <td>0</td>\n      <td>5</td>\n      <td>491</td>\n      <td>268</td>\n      <td>23</td>\n      <td>421</td>\n      <td>268</td>\n      <td>2000.0</td>\n      <td>136.0</td>\n      <td>-640.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>70.063</td>\n      <td>160.0</td>\n      <td>12.964</td>\n      <td>0.000000</td>\n      <td>10.0</td>\n      <td>1031.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv('../data/datasets/cleanDataConfig.csv', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(733822, 41)"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_names = df.columns.to_list()\n",
    "\n",
    "predictors = columns_names[:38]\n",
    "\n",
    "target = columns_names[-1]\n",
    "\n",
    "X = df[predictors]\n",
    "\n",
    "Y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , Y_train , Y_test = train_test_split(X , Y , test_size=0.2, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest(jobs=7):\n",
    "    depht = [1,2,3,4,5,7,10,13,15,18,None]\n",
    "    min_samples_split = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    min_samples_leaf = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "    print(\"RANDOM FOREST: INICIO PROFUNDIDAD\")\n",
    "    forest = RandomForestClassifier(n_jobs=jobs, n_estimators=200)\n",
    "    \n",
    "    # Obtenemos la curva de validacion variando la profundidad\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        estimator = forest,\n",
    "        X = X_train,\n",
    "        y = Y_train,\n",
    "        param_name='max_depth',\n",
    "        param_range=depht,\n",
    "        cv=ms.StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    )\n",
    "\n",
    "    data = [train_scores, test_scores]\n",
    "\n",
    "    with open('../data/serialized/randomForestPROFUNDIDAD.sav', 'wb') as file:\n",
    "        pickle.dump(data, file, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open('../data/resultados/curvaValidacion/resultados.csv', 'a', encoding='utf-8') as file:\n",
    "        file.write(f\"RANDOM_FOREST;PROFUNDIDAD;{train_scores.mean()};{test_scores.mean()}\\n\")\n",
    "\n",
    "\n",
    "    print(\"RANDOM FOREST: PROFUNDIDAD TERMINADA\")\n",
    "    print(\"RANDOM FOREST: INICIO MIN SAMPLES SPLIT\")\n",
    "\n",
    "    # Obtenemos la curva de validacion variando el numero minimo de ejemplos para dividir un nodo\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        estimator = forest,\n",
    "        X = X_train,\n",
    "        y = Y_train,\n",
    "        param_name='min_samples_split',\n",
    "        param_range=min_samples_split,\n",
    "        cv=ms.StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    )\n",
    "\n",
    "    data = [train_scores, test_scores]\n",
    "\n",
    "    with open('../data/serialized/randomForestEJEMPLOS_SPLIT.sav', 'wb') as file:\n",
    "        pickle.dump(data, file, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open('../data/resultados/curvaValidacion/resultados.csv', 'a', encoding='utf-8') as file:\n",
    "        file.write(f\"RANDOM_FOREST;MIN_SAMPLES_SPLIT;{train_scores.mean()};{test_scores.mean()}\\n\")\n",
    "\n",
    "\n",
    "    print(\"RANDOM FOREST: MIN SAMPLES SPLIT TERMINADA\")\n",
    "    print(\"RANDOM FOREST: INICIO MIN min_samples_leaf\")\n",
    "\n",
    "    # Obtenemos la curva de validacion variando el numero minimo de ejemplos por hoja\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        estimator = forest,\n",
    "        X = X_train,\n",
    "        y = Y_train,\n",
    "        param_name='min_samples_leaf',\n",
    "        param_range=min_samples_leaf,\n",
    "        cv=ms.StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    )\n",
    "\n",
    "    data = [train_scores, test_scores]\n",
    "\n",
    "    with open('../data/serialized/randomForestEJEMPLOS_HOJAS.sav', 'wb') as file:\n",
    "        pickle.dump(data, file, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open('../data/resultados/curvaValidacion/resultados.csv', 'a', encoding='utf-8') as file:\n",
    "        file.write(f\"RANDOM_FOREST;MIN_SAMPLES_LEAF;{train_scores.mean()};{test_scores.mean()}\\n\")\n",
    "\n",
    "\n",
    "    print(\"RANDOM FOREST: min_samples_leaf TERMINADO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(jobs=7):\n",
    "    distances = ['euclidean','manhattan', 'chebyshev', 'minkowski']\n",
    "    vecinos = [5,7,9]\n",
    "\n",
    "    for idx, vecino in enumerate(vecinos):    \n",
    "        print(f\"KNN ==> Vecino {idx+1} de {len(vecinos)}\")\n",
    "        # Obtenemos la curva de validacion variando los vecinos y el calculo de la distancia\n",
    "        knn = KNeighborsClassifier(n_neighbors=vecino, n_jobs=jobs)\n",
    "        train_scores, test_scores = validation_curve(\n",
    "            estimator = knn\n",
    "            X = X_train,\n",
    "            y = Y_train,\n",
    "            param_name='metric',\n",
    "            param_range=distances,\n",
    "            cv=ms.StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "        )\n",
    "\n",
    "        data = [train_scores, test_scores]\n",
    "\n",
    "        with open(f'../data/serialized/knnVC{vecino}.sav', 'wb') as file:\n",
    "            pickle.dump(data, file, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        with open('../data/resultados/curvaValidacion/resultados.csv', 'a', encoding='utf-8') as file:\n",
    "            file.write(f\"KNN;METRIC;{train_scores.mean()};{test_scores.mean()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrnn(jobs=7):\n",
    "    print(\"Inicio RRNN\")\n",
    "    epocas = [10,20,50,100,150,200]\n",
    "\n",
    "    print(\"INICIO RED NEURONAL\")\n",
    "\n",
    "    rrnn = MLPClassifier(hidden_layer_sizes=(38,25,40,35), random_state=0)\n",
    "    \n",
    "    # Obtenemos la curva de validacion variando el numero de epocas\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        estimator = rrnn,\n",
    "        X = X_train,\n",
    "        y = Y_train,\n",
    "        param_name='max_iter',\n",
    "        param_range=epocas,\n",
    "        cv=ms.StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    )\n",
    "\n",
    "    data = [train_scores, test_scores]\n",
    "\n",
    "    with open('../data/serialized/rrNN-DEF.sav', 'wb') as file:\n",
    "        pickle.dump(data, file, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(jobs=7):\n",
    "    try:\n",
    "        print(\"COMIENZO RANDOM FOREST\")\n",
    "        randomForest(jobs)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR en el RANDOM FOREST. ERROR \\n {e}\")\n",
    "        pass\n",
    "    try:\n",
    "        print(\"COMIENZO KNN\")\n",
    "        knn(jobs)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR en el KNN. ERROR \\n {e}\")\n",
    "        pass    \n",
    "    try:\n",
    "        print(\"COMIENZO RNNN\")\n",
    "        rrnn(jobs)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR en el KNN. ERROR \\n {e}\")\n",
    "        pass \n",
    "    print(\"FINNNNN!!!!!!!!!!!!\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "COMIENZO RANDOM FOREST\nRANDOM FOREST: INICIO PROFUNDIDAD\nRANDOM FOREST: PROFUNDIDAD TERMINADA\nRANDOM FOREST: INICIO MIN SAMPLES SPLIT\nRANDOM FOREST: MIN SAMPLES SPLIT TERMINADA\nRANDOM FOREST: INICIO MIN min_samples_leaf\nRANDOM FOREST: min_samples_leaf TERMINADO\nCOMIENZO KNN\nKNN ==> Vecino 1 de 3\nKNN ==> Vecino 2 de 3\nKNN ==> Vecino 3 de 3\nCOMIENZO RNNN\nInicio RRNN\nINICIO RED NEURONAL\nFINNNNN!!!!!!!!!!!!\n"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg",
   "language": "python",
   "name": "tfg"
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.7.0-final"
 },
 "orig_nbformat": 2,
 "kernelspec": {
  "name": "python37064bittfgconda3a3537ca45d749f9a68dd860a63d18da",
  "display_name": "Python 3.7.0 64-bit ('tfg': conda)"
 }
}