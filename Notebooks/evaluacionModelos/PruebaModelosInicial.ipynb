{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   id_leg  operation  runway  hexid  callsign  type  origin  destination  \\\n0  733513          0       5    483      6920    22     186          268   \n1  733498          0       5    515       246    23     664          268   \n2  733495          0       5    814       262    67     212          268   \n3  733501          0       5    625       277    23     254          268   \n4  733496          0       5    491       268    23     421          268   \n\n   altitude  ground_speed  vertical_rate  tmp  dew_pt  rel_hum  wind_dir  \\\n0    1625.0         142.0         -768.0  7.0     0.0   61.017     250.0   \n1    1850.0         137.0         -768.0  7.0    -1.0   56.724     250.0   \n2    2200.0         156.0         -832.0  7.0    -1.0   56.724     230.0   \n3    1862.5         143.0         -640.0  7.0    -1.0   56.724     230.0   \n4    2000.0         136.0         -640.0  5.0     0.0   70.063     160.0   \n\n   win_sp  wind_gust  visib   press  sky_lvl  rain  snow  drizzle  fog  \\\n0  20.372   0.000000   10.0  1030.0     10.0   0.0   0.0      0.0  0.0   \n1  25.928  44.447962   10.0  1030.0     10.0   0.0   0.0      0.0  0.0   \n2  16.668   0.000000   10.0  1031.0     10.0   0.0   0.0      0.0  0.0   \n3  16.668   0.000000   10.0  1031.0     10.0   0.0   0.0      0.0  0.0   \n4  12.964   0.000000   10.0  1031.0     10.0   0.0   0.0      0.0  0.0   \n\n   time_class  day_week  month  time_ref  operation_Landing  \\\n0         2.0       1.0    1.0       6.0                1.0   \n1         3.0       1.0    1.0       7.0                1.0   \n2         3.0       1.0    1.0       8.0                1.0   \n3         3.0       1.0    1.0       8.0                1.0   \n4         4.0       1.0    1.0       9.0                1.0   \n\n   operation_TakeOff  runway_14L  runway_14R  runway_18L  runway_18R  \\\n0                0.0         0.0         0.0         0.0         0.0   \n1                0.0         0.0         0.0         0.0         0.0   \n2                0.0         0.0         0.0         0.0         0.0   \n3                0.0         0.0         0.0         0.0         0.0   \n4                0.0         0.0         0.0         0.0         0.0   \n\n   runway_32L  runway_32R  runway_36L  runway_36R  configuration_NORTE  \\\n0         0.0         1.0         0.0         0.0                    1   \n1         0.0         1.0         0.0         0.0                    1   \n2         0.0         1.0         0.0         0.0                    1   \n3         0.0         1.0         0.0         0.0                    1   \n4         0.0         1.0         0.0         0.0                    1   \n\n   configuration_SUR  configuration  \n0                  0              0  \n1                  0              0  \n2                  0              0  \n3                  0              0  \n4                  0              0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_leg</th>\n      <th>operation</th>\n      <th>runway</th>\n      <th>hexid</th>\n      <th>callsign</th>\n      <th>type</th>\n      <th>origin</th>\n      <th>destination</th>\n      <th>altitude</th>\n      <th>ground_speed</th>\n      <th>vertical_rate</th>\n      <th>tmp</th>\n      <th>dew_pt</th>\n      <th>rel_hum</th>\n      <th>wind_dir</th>\n      <th>win_sp</th>\n      <th>wind_gust</th>\n      <th>visib</th>\n      <th>press</th>\n      <th>sky_lvl</th>\n      <th>rain</th>\n      <th>snow</th>\n      <th>drizzle</th>\n      <th>fog</th>\n      <th>time_class</th>\n      <th>day_week</th>\n      <th>month</th>\n      <th>time_ref</th>\n      <th>operation_Landing</th>\n      <th>operation_TakeOff</th>\n      <th>runway_14L</th>\n      <th>runway_14R</th>\n      <th>runway_18L</th>\n      <th>runway_18R</th>\n      <th>runway_32L</th>\n      <th>runway_32R</th>\n      <th>runway_36L</th>\n      <th>runway_36R</th>\n      <th>configuration_NORTE</th>\n      <th>configuration_SUR</th>\n      <th>configuration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>733513</td>\n      <td>0</td>\n      <td>5</td>\n      <td>483</td>\n      <td>6920</td>\n      <td>22</td>\n      <td>186</td>\n      <td>268</td>\n      <td>1625.0</td>\n      <td>142.0</td>\n      <td>-768.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>61.017</td>\n      <td>250.0</td>\n      <td>20.372</td>\n      <td>0.000000</td>\n      <td>10.0</td>\n      <td>1030.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>733498</td>\n      <td>0</td>\n      <td>5</td>\n      <td>515</td>\n      <td>246</td>\n      <td>23</td>\n      <td>664</td>\n      <td>268</td>\n      <td>1850.0</td>\n      <td>137.0</td>\n      <td>-768.0</td>\n      <td>7.0</td>\n      <td>-1.0</td>\n      <td>56.724</td>\n      <td>250.0</td>\n      <td>25.928</td>\n      <td>44.447962</td>\n      <td>10.0</td>\n      <td>1030.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>733495</td>\n      <td>0</td>\n      <td>5</td>\n      <td>814</td>\n      <td>262</td>\n      <td>67</td>\n      <td>212</td>\n      <td>268</td>\n      <td>2200.0</td>\n      <td>156.0</td>\n      <td>-832.0</td>\n      <td>7.0</td>\n      <td>-1.0</td>\n      <td>56.724</td>\n      <td>230.0</td>\n      <td>16.668</td>\n      <td>0.000000</td>\n      <td>10.0</td>\n      <td>1031.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>733501</td>\n      <td>0</td>\n      <td>5</td>\n      <td>625</td>\n      <td>277</td>\n      <td>23</td>\n      <td>254</td>\n      <td>268</td>\n      <td>1862.5</td>\n      <td>143.0</td>\n      <td>-640.0</td>\n      <td>7.0</td>\n      <td>-1.0</td>\n      <td>56.724</td>\n      <td>230.0</td>\n      <td>16.668</td>\n      <td>0.000000</td>\n      <td>10.0</td>\n      <td>1031.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>733496</td>\n      <td>0</td>\n      <td>5</td>\n      <td>491</td>\n      <td>268</td>\n      <td>23</td>\n      <td>421</td>\n      <td>268</td>\n      <td>2000.0</td>\n      <td>136.0</td>\n      <td>-640.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>70.063</td>\n      <td>160.0</td>\n      <td>12.964</td>\n      <td>0.000000</td>\n      <td>10.0</td>\n      <td>1031.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/datasets/cleanDataConfig.csv\" , sep=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(733822, 41)"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_names = df.columns.to_list()\n",
    "\n",
    "predictors = columns_names[:38]\n",
    "\n",
    "target = columns_names[-1]\n",
    "\n",
    "X = df[predictors]\n",
    "\n",
    "Y = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest():\n",
    "    filename = '../data/resultados/evaluacionModelos/randomForest.csv'\n",
    "    estimators = [10,20,50,100,150,200,250,300,400,500,550,600,650,700,750,800,850,900]\n",
    "    \n",
    "    X_train , X_test , Y_train , Y_test = train_test_split(X_full , Y_full , test_size=0.2, shuffle=True, random_state=0)\n",
    "\n",
    "    for estimator in estimators:\n",
    "        forest_full = RandomForestClassifier(oob_score=True , n_estimators=estimator, n_jobs=2)\n",
    "        forest_full.fit(X_train , Y_train)\n",
    "        score = forest_full.oob_score_\n",
    "\n",
    "        with open (filename , 'a' , encoding='utf-8') as file:\n",
    "            file.write(f\"FULL;{estimator};{score}\\n\")\n",
    "    \n",
    "    print(\"Random Forest FULL Completado!!\")\n",
    "    \n",
    "    X_train , X_test , Y_train , Y_test = train_test_split(X_full , Y_unique , test_size=0.2, shuffle=True, random_state=0)\n",
    "\n",
    "    for idx, estimator in enumerate(estimators):                \n",
    "        forest_full_targetNorm = RandomForestClassifier(oob_score=True , n_estimators=estimator, n_jobs=3)\n",
    "        forest_full_targetNorm.fit(X_train , Y_train)\n",
    "        score = forest_full_targetNorm.oob_score_ \n",
    "        with open (filename , 'a' , encoding='utf-8') as file:\n",
    "            file.write(f\"FNORM;{estimator};{score}\\n\")\n",
    "\n",
    "    print(\"Random Forest FNORM Completado!!\")            \n",
    "    \n",
    "    X_train , X_test , Y_train , Y_test = train_test_split(X_related , Y_full , test_size=0.2, shuffle=True, random_state=0)\n",
    "\n",
    "    for idx, estimator in enumerate(estimators):  \n",
    "        related_forest = RandomForestClassifier(oob_score=True , n_estimators=estimator, n_jobs=3)\n",
    "        related_forest.fit(X_train , Y_train)\n",
    "        score = related_forest.oob_score_\n",
    "        with open (filename , 'a' , encoding='utf-8') as file:\n",
    "            file.write(f\"RELATED;{estimator};{score}\\n\")\n",
    "            \n",
    "    print(\"Random Forest RELATED Completado!!\")            \n",
    "   \n",
    "    X_train , X_test , Y_train , Y_test = train_test_split(X_related , Y_unique , test_size=0.2, shuffle=True, random_state=0)\n",
    "    \n",
    "    for idx, estimator in enumerate(estimators):  \n",
    "        related_forest_targetNorm = RandomForestClassifier(oob_score=True , n_estimators=estimator, n_jobs=3)\n",
    "        related_forest_targetNorm.fit(X_train , Y_train)\n",
    "        score = related_forest_targetNorm.oob_score_\n",
    "        \n",
    "        with open (filename , 'a' , encoding='utf-8') as file:\n",
    "            file.write(f\"RNORM;{estimator};{score}\\n\")\n",
    "    \n",
    "    print(\"Random Forest RNORM Completado!!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn():\n",
    "    filename = '../data/resultados/evaluacionModelos/knn.csv'\n",
    "    neighbors = [x for x in range(72) if x % 2 != 0]\n",
    "    \n",
    "    X_train , X_test , Y_train , Y_test = train_test_split(X_full , Y_full , test_size=0.2, shuffle=True, random_state=0)\n",
    "\n",
    "    for idx, n in enumerate(neighbors):\n",
    "        knn_full = KNeighborsClassifier(n_neighbors=n , metric='euclidean', n_jobs=3)\n",
    "        knn_full.fit(X_train , Y_train)\n",
    "\n",
    "        knn_accuracy = knn_full.score(X_test , Y_test)\n",
    "        with open (filename , 'a' , encoding='utf-8') as file:\n",
    "            file.write(\"FULL;{};{}\".format(n , knn_accuracy) + '\\n')\n",
    "\n",
    "\n",
    "    print(\"KNN FULL Completado!!\")\n",
    "            \n",
    "    X_train , X_test , Y_train , Y_test = train_test_split(X_full , Y_unique , test_size=0.2, shuffle=True, random_state=0)\n",
    "    \n",
    "    for idx, n in enumerate(neighbors):\n",
    "        knn_full_targetNorm = KNeighborsClassifier(n_neighbors=n , metric='euclidean', n_jobs=3)\n",
    "        knn_full_targetNorm.fit(X_train , Y_train)\n",
    "\n",
    "        knn_accuracy = knn_full_targetNorm.score(X_test , Y_test)\n",
    "        with open (filename , 'a' , encoding='utf-8') as file:\n",
    "            file.write(\"FNORM;{};{}\".format(n , knn_accuracy) + '\\n')\n",
    "            \n",
    "            \n",
    "    print(\"KNN FNORM Completado!!\")\n",
    "\n",
    "    X_train , X_test , Y_train , Y_test = train_test_split(X_related , Y_full , test_size=0.2, shuffle=True, random_state=0)\n",
    "\n",
    "    for idx, n in enumerate(neighbors):\n",
    "        related_knn_full = KNeighborsClassifier(n_neighbors=n , metric='euclidean', n_jobs=3)\n",
    "        related_knn_full.fit(X_train , Y_train)\n",
    "\n",
    "        knn_accuracy = related_knn_full.score(X_test , Y_test)\n",
    "        with open (filename , 'a' , encoding='utf-8') as file:\n",
    "            file.write(\"RELATED;{};{}\".format(n , knn_accuracy) + '\\n')\n",
    "            \n",
    "    print(\"KNN RELATED Completado!!\")\n",
    "    \n",
    "    X_train , X_test , Y_train , Y_test = train_test_split(X_related , Y_unique , test_size=0.2, shuffle=True, random_state=0)\n",
    "    \n",
    "    for idx, n in enumerate(neighbors):\n",
    "        related_knn_targetNorm = KNeighborsClassifier(n_neighbors=n , metric='euclidean', n_jobs=3)\n",
    "        related_knn_targetNorm.fit(X_train , Y_train)\n",
    "\n",
    "        knn_accuracy = related_knn_targetNorm.score(X_test , Y_test)\n",
    "        with open (filename , 'a' , encoding='utf-8') as file:\n",
    "            file.write(\"RNORM;{};{}\".format(n , knn_accuracy) + '\\n')\n",
    "            \n",
    "    print(\"KNN RNORM Completado!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegresion():\n",
    "    filename = '../data/resultados/evaluacionModelos/logisticRegresion.csv'\n",
    "\n",
    "    X_train , X_test , Y_train , Y_test = train_test_split(X_full , Y_unique , test_size=0.2, shuffle=True, random_state=0)\n",
    "\n",
    "    lr_full = LogisticRegression()\n",
    "    lr_full.fit(X_train, Y_train)\n",
    "    preds_train_default = lr_full.predict(X_train)\n",
    "    preds_test_default = lr_full.predict(X_test)\n",
    "    with open (filename, 'a', encoding='utf-8') as file:\n",
    "        file.write(f\"FULL;{accuracy_score(preds_train_default, Y_train)};{accuracy_score(preds_test_default, Y_test)}\\n\")\n",
    "\n",
    "    X_train , X_test , Y_train , Y_test = train_test_split(X_related , Y_unique , test_size=0.2, shuffle=True, random_state=0)\n",
    "   \n",
    "    related_lr = LogisticRegression()\n",
    "    related_lr.fit(X_train, Y_train)\n",
    "    preds_train_default = related_lr.predict(X_train)\n",
    "    preds_test_default = related_lr.predict(X_test)\n",
    "    with open (filename, 'a', encoding='utf-8') as file:\n",
    "        file.write(f\"RNORM;{accuracy_score(preds_train_default, Y_train)};{accuracy_score(preds_test_default, Y_test)}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuralNetworks():\n",
    "    epocas = [10,20,40,60,80,100,150,200]\n",
    "    filename = '../data/resultados/evaluacionModelos/redesNeuronalesRestantes.csv'\n",
    "    activation = ['relu','identity','logistic','tanh']\n",
    "\n",
    "    X_train , X_test , Y_train , Y_test = train_test_split(X_full , Y_full , test_size=0.2, shuffle=True, random_state=0)\n",
    "    \n",
    "    for idx, epoca in enumerate(epocas):\n",
    "        for funtion in activation:\n",
    "            mlp_full = MLPClassifier(activation=funtion , solver='adam' , max_iter=epoca)\n",
    "            mlp_full.fit(X_train , Y_train)\n",
    "            \n",
    "            accuracy = mlp_full.score(X_test , Y_test)\n",
    "            with open (filename , 'a' , encoding='utf-8') as file:\n",
    "                file.write(\"FULL;{};{};{}\\n\".format(funtion,accuracy,epoca))\n",
    "                \n",
    "    print(\"Redes Nueronales FULL Completado!!\")\n",
    "    \n",
    "    X_train , X_test , Y_train , Y_test = train_test_split(X_full , Y_unique , test_size=0.2, shuffle=True, random_state=0)\n",
    "\n",
    "    for idx, epoca in enumerate(epocas):\n",
    "        for funtion in activation:\n",
    "            mlp_norm = MLPClassifier(activation=funtion , solver='adam' , max_iter=epoca)\n",
    "            mlp_norm.fit(X_train , Y_train)\n",
    "            accuracy = mlp_norm.score(X_test , Y_test)\n",
    "            with open (filename , 'a' , encoding='utf-8') as file:\n",
    "                file.write(\"FNORM;{};{};{}\\n\".format(funtion,accuracy,epoca))\n",
    "\n",
    "                \n",
    "    print(\"Redes Nueronales FNORM Completado!!\")\n",
    "                \n",
    "    X_train , X_test , Y_train , Y_test = train_test_split(X_related , Y_full , test_size=0.2, shuffle=True, random_state=0)\n",
    "\n",
    "    for idx, epoca in enumerate(epocas):\n",
    "        for funtion in activation:\n",
    "            mlp_related = MLPClassifier(activation=funtion , solver='adam' , max_iter=epoca)\n",
    "            mlp_related.fit(X_train , Y_train)\n",
    "            accuracy = mlp_related.score(X_test , Y_test)\n",
    "            \n",
    "            with open (filename , 'a' , encoding='utf-8') as file:\n",
    "                file.write(\"RELATED;{};{};{}\\n\".format(funtion,accuracy,epoca))\n",
    "                \n",
    "    print(\"Redes Nueronales RELATED Completado!!\")\n",
    "\n",
    "    X_train , X_test , Y_train , Y_test = train_test_split(X_related , Y_unique , test_size=0.2, shuffle=True, random_state=0)\n",
    "\n",
    "    for idx, epoca in enumerate(epocas):\n",
    "        for funtion in activation:    \n",
    "            mlp_related_unique = MLPClassifier(activation=funtion , solver='adam' , max_iter=epoca)\n",
    "            mlp_related_unique.fit(X_train , Y_train)\n",
    "\n",
    "            accuracy = mlp_related_unique.score(X_test , Y_test)\n",
    "        \n",
    "            with open (filename , 'a' , encoding='utf-8') as file:\n",
    "                file.write(\"RNORM;{};{};{}\\n\".format(funtion,accuracy,epoca))\n",
    "                \n",
    "    print(\"Redes Nueronales RNORM Completado!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Inicio prueba modelos\")\n",
    "    try:\n",
    "        randomForest()\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR. Se ha producido un error en el RANDOM FOREST. Error:\\n{e}\")\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        knn()\n",
    "        print(\"Fin del KNN\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR. Se ha producido un error en el KNN. Error:\\n{e}\")\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        logisticRegresion()\n",
    "        print(\"Fin de la Regresion Logistica\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR. Se ha producido un error en la Regresion Logistica. Error:\\n{e}\")\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        neuralNetworks()\n",
    "        print(\"Fin de las Redes Neuronales\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR. Se ha producido un error en las Redes Neuronales. Error:\\n{e}\")\n",
    "        pass\n",
    "        \n",
    "    print(\"Fin prueba modelos!!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Inicio prueba modelos\nRandom Forest FULL Completado!!\nRandom Forest FNORM Completado!!\nRandom Forest RELATED Completado!!\nRandom Forest RNORM Completado!!\nFin del RANDOM FOREST\nKNN FULL Completado!!\nKNN FNORM Completado!!\nKNN RELATED Completado!!\nKNN RNORM Completado!!\nFin del KNN\nFin de la Regresion Logistica\nRedes Nueronales FULL Completado!!\nRedes Nueronales FNORM Completado!!\nRedes Nueronales RELATED Completado!!\nRedes Nueronales RNORM Completado!!\nFin de las Redes Neuronales\nFin prueba modelos!!!!!!!\n"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('tfg': conda)",
   "language": "python",
   "name": "python37064bittfgconda3a3537ca45d749f9a68dd860a63d18da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}